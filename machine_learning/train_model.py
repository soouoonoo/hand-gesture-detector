import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
import joblib
import os

def load_data():
    """åŠ è½½æ”¶é›†çš„æ•°æ®"""
    features = np.load("gesture_data/features.npy")
    labels = np.load("gesture_data/labels.npy")
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {features.shape[0]} ä¸ªæ ·æœ¬, {features.shape[1]} ä¸ªç‰¹å¾")
    print(f"ğŸ”¢ æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels.astype(int))}")
    return features, labels

def train_simple_model():
    """è®­ç»ƒç®€å•çš„æœºå™¨å­¦ä¹ æ¨¡å‹"""
    
    # 1. åŠ è½½æ•°æ®
    X, y = load_data()
    
    # 2. æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"è®­ç»ƒé›†: {X_train.shape[0]}, æµ‹è¯•é›†: {X_test.shape[0]}")
    
    # 3. ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆé‡è¦ï¼ï¼‰
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 4. è®­ç»ƒå¤šä¸ªæ¨¡å‹æ¯”è¾ƒ
    models = {
        "KNN": KNeighborsClassifier(n_neighbors=5),
        "SVM": SVC(kernel='rbf', probability=True),
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42)
    }
    
    best_model = None
    best_score = 0
    
    for name, model in models.items():
        print(f"\nè®­ç»ƒ {name}...")
        model.fit(X_train_scaled, y_train)
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)
        
        print(f"  è®­ç»ƒå‡†ç¡®ç‡: {train_score:.3f}")
        print(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_score:.3f}")
        
        if test_score > best_score:
            best_score = test_score
            best_model = model
            best_model_name = name
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (å‡†ç¡®ç‡: {best_score:.3f})")
    
    # 5. ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
    joblib.dump(best_model, "model.pkl")
    joblib.dump(scaler, "scaler.pkl")
    
    # 6. è¯„ä¼°æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    print("\nğŸ“ˆ æ¯ä¸ªæ‰‹åŠ¿çš„å‡†ç¡®ç‡:")
    y_pred = best_model.predict(X_test_scaled)
    unique_labels = np.unique(y_test)
    
    label_names = ["zero", "one", "two", "three", "four", "five", 
                  "six", "seven", "eight", "nine", "ten"]
    
    for label in unique_labels:
        idx = y_test == label
        accuracy = (y_pred[idx] == label).mean()
        print(f"  {label_names[int(label)]}({int(label)}): {accuracy:.3f}")
    
    return best_model, scaler

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ‰‹åŠ¿è¯†åˆ«æ¨¡å‹...")
    model, scaler = train_simple_model()
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼ä¿å­˜ä¸º model.pkl å’Œ scaler.pkl")