"""
ç½‘é¡µç¨‹åºï¼Œä¾‹ï¼šåœ¨ç»ˆç«¯æ‰§è¡Œstreamlit run /.../packed_by_streamlit.py
è¯·å…ˆåœ¨test_specific_methodè°ƒè¯•ï¼Œåšå¥½å•ä¸€æ–¹æ³•å†ä»è¿™é‡Œä½¿ç”¨
"""
import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(__file__))) #æ·»åŠ å¼•ç”¨è·¯å¾„

# ç›´æ¥ä»utilsæ¨¡å—å¯¼å…¥æ£€æµ‹æ–¹æ³•
from multiple_hand_gestures import MultipleHandGestures

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ‰‹åŠ¿æ£€æµ‹",
    page_icon="ğŸ‘†",
    layout="centered"
)

st.title("ğŸ‘† ç®€å•æ‰‹åŠ¿æ£€æµ‹")
st.markdown("æ£€æµ‹ **'æ¯”ä¸€'** æ‰‹åŠ¿ï¼ˆé£ŸæŒ‡ä¼¸ç›´ï¼Œå…¶ä»–æ‰‹æŒ‡å¼¯æ›²ï¼‰")

# åˆå§‹åŒ–MediaPipe
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# åˆ›å»ºå ä½ç¬¦
status_text = st.empty()
image_placeholder = st.empty()

# ç®€å•çš„æ£€æµ‹å‡½æ•°
def detect_pointing_gesture():
    """æ£€æµ‹'æ¯”ä¸€'æ‰‹åŠ¿çš„ä¸»å‡½æ•°"""

    # åˆ›å»ºæ‘„åƒå¤´å¯¹è±¡
    cap = cv2.VideoCapture(0)

    # è®¾ç½®æ‘„åƒå¤´å‚æ•°
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # åˆå§‹åŒ–æ‰‹åŠ¿æ£€æµ‹å™¨
    with mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as hands:

        detecting = True
        while detecting:
            # è¯»å–å¸§
            success, frame = cap.read()
            if not success:
                status_text.warning("æ— æ³•è¯»å–æ‘„åƒå¤´")
                break

            # é•œåƒç¿»è½¬
            frame = cv2.flip(frame, 1)
            height, width, _ = frame.shape

            # è½¬æ¢é¢œè‰²ç©ºé—´
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # æ£€æµ‹æ‰‹åŠ¿
            results = hands.process(rgb_frame)

            # æ£€æµ‹çŠ¶æ€
            gesture_detected = False
            score_info = ""

            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    # ç»˜åˆ¶å…³é”®ç‚¹
                    mp_drawing.draw_landmarks(
                        frame, 
                        hand_landmarks, 
                        mp_hands.HAND_CONNECTIONS
                    )

                    # ä½¿ç”¨æ‚¨çš„DetectNumberOneæ–¹æ³•è¿›è¡Œæ£€æµ‹
                    detected, score, total = MultipleHandGestures.DetectNumberOne(hand_landmarks, (height, width), debug=False)

                    if detected:
                        gesture_detected = True
                        score_info = f"âœ… æ£€æµ‹åˆ°æ‰‹åŠ¿ (åˆ†æ•°: {score}/{total})"

                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        landmarks = hand_landmarks.landmark
                        x_coords = [int(lm.x * width) for lm in landmarks]
                        y_coords = [int(lm.y * height) for lm in landmarks]
                        x_min, x_max = min(x_coords), max(x_coords)
                        y_min, y_max = min(y_coords), max(y_coords)

                        cv2.rectangle(frame, 
                                     (x_min-20, y_min-20), 
                                     (x_max+20, y_max+20), 
                                     (0, 255, 0), 3)

                        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                        cv2.putText(frame, "POINTING DETECTED", 
                                   (x_min, y_min-30), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                        # æ˜¾ç¤ºåˆ†æ•°
                        cv2.putText(frame, f"Score: {score}/{total}", 
                                   (x_min, y_min-60), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

                        status_text.success(score_info)
                    else:
                        score_info = f"ğŸ‘‹ æœªæ£€æµ‹åˆ° (åˆ†æ•°: {score}/{total})"
                        status_text.info(score_info)

            # æ˜¾ç¤ºçŠ¶æ€
            if not results.multi_hand_landmarks:
                status_text.info("ğŸ–ï¸ æœªæ£€æµ‹åˆ°æ‰‹éƒ¨")

            # è½¬æ¢ä¸ºRGBæ˜¾ç¤º
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # æ˜¾ç¤ºå›¾åƒ
            image_placeholder.image(frame_rgb, channels="RGB")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            detecting = True  # è¿™é‡Œå¯ä»¥é€šè¿‡å¤–éƒ¨å˜é‡æ§åˆ¶

    # é‡Šæ”¾èµ„æº
    cap.release()
    cv2.destroyAllWindows()

# ä¸»ç•Œé¢
if st.button("ğŸ¥ å¼€å§‹æ£€æµ‹", type="primary"):
    # å¼€å§‹æ£€æµ‹
    detect_pointing_gesture()

st.markdown("---")
st.markdown("""
### ğŸ“ ä½¿ç”¨è¯´æ˜
1. ç‚¹å‡» **å¼€å§‹æ£€æµ‹** æŒ‰é’®
2. é¢å¯¹æ‘„åƒå¤´
3. åšå‡º **'æ¯”ä¸€'** æ‰‹åŠ¿ï¼š
   - é£ŸæŒ‡å®Œå…¨ä¼¸ç›´
   - å…¶ä»–æ‰‹æŒ‡å¼¯æ›²
4. æ£€æµ‹åˆ°æ‰‹åŠ¿ä¼šæœ‰ç»¿è‰²è¾¹æ¡†æç¤º
5. å·¦ä¸Šè§’æ˜¾ç¤ºæ£€æµ‹åˆ†æ•°
""")